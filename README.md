---
title: Reports of Large Language Models
date: 2025-01-28
tags: 
- AI
categories: 
- 2025
- 2025-01
---



| Date       | Name | Report | Open Source? |
| ---------- | ---- | ------ | ---------- |
| 2022-01-27 | InstructGPT | [NeurlPS 2022](https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf) [1] | No |
| 2022-11-30 | ChatGPT-3.5 | [blog post](https://openai.com/index/chatgpt/) | No |
| 2023-03-04 | ChatGPT-4 | [arxiv](https://arxiv.org/html/2303.08774v6) [2] | No |
| 2024-07-23 | Llama 3 & 3.1 | [arxiv](https://arxiv.org/pdf/2407.21783) | Yes |
| 2024-09-12 | ChatGPT-o1 | [blog post](https://openai.com/index/learning-to-reason-with-llms/) | No |
| 2024-12-21 | ChatGPT-o3 | [blog post](https://www.youtube.com/watch?v=SKBG1sqdyIU) [3] | No |
| 2024-12-27 | DeepSeek V3 | [arxiv](https://arxiv.org/html/2412.19437v1) [4] |  Yes  |
| 2025-01-22 |   DeepSeek R1   | [arxiv](https://arxiv.org/html/2501.12948v1) [4] |  Yes  |
| 2025-01-22 | Kimi 1.5 | [arxiv](https://arxiv.org/html/2501.12599v1) | No |

Note:

1. Typically, clarity: conference > arxiv > blog post. So, If a model is documented in all three formats (conference, arxiv, and blog post), only the conference link will be recorded in this table.
2. OpenAI published a "technical report" of GPT-4 on arxiv. That is, this arxiv paper contains no additional technical details compared to its [blog post](https://openai.com/index/gpt-4-research/). Similarly, [Google's arxiv papers](https://arxiv.org/pdf/2403.05530) also tell you nothing more about Gemini.
3. OpenAI published a video containing the performances of ChatGPT-o3 on YouTube.
4. [DeepSeek V3 and R1 uses 2,664,000 H800 GPU hours, while LLAMA 3 uses 39,300,000 H800 GPU hours.](https://mp.weixin.qq.com/s/xVux1jo1nLpSSrt7JlxfKA) 
